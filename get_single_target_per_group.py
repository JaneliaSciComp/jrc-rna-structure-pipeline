import pandas as pd


if __name__ == "__main__":
    import argparse
    from pathlib import Path

    parser = argparse.ArgumentParser(
        description="Get single target per group, merge metadata by taking first occurrence after sorting by specified columns or text merging if requested"
    )
    parser.add_argument(
        "input_file", type=str, help="Path to the CSV file with sequences"
    )
    parser.add_argument(
        "output_file", type=str, help="Output CSV file with single sequence per group"
    )

    parser.add_argument(
        "--add_group_index_file",
        type=str,
        default=None,
        help="Optional file to store original file with added index of each entry in the group",
    )
    parser.add_argument(
        "--group_index_name",
        type=str,
        default="group_index",
        help="Name of the group index column to add if add_group_index_file is specified",
    )

    parser.add_argument(
        "--sort_by",
        nargs="+",
        type=str,
        default=["temporal_cutoff", "target_id"],
        help="Columns to sort by before merging",
    )
    parser.add_argument(
        "--merge",
        nargs="+",
        type=str,
        default=None,
        help="Columns to merge after sorting",
    )

    parser.add_argument(
        "--drop",
        nargs="+",
        type=str,
        default=None,
        help="Columns to drop before saving",
    )

    parser.add_argument(
        "--group-key", type=str, default="group_id", help="Column defining groups"
    )

    parser.add_argument(
        "--rename",
        nargs=2,
        action="append",
        metavar=("old_name", "new_name"),
        help="Rename columns after processing, applied in order",
    )

    parser.add_argument(
        "--sort_by_after",
        nargs="+",
        type=str,
        default=["temporal_cutoff", "target_id"],
        help="Columns to sort by after merging",
    )

    parser.add_argument(
        "--multichain",
        action="store_true",
        help="Indicates multiple entries separated by ; in group-key column. Compared independent of order (sorted before comparison).",
    )

    args = parser.parse_args()
    input_file = Path(args.input_file)
    output_file = Path(args.output_file)
    targets = pd.read_csv(input_file, keep_default_na=False)

    # Sort and merge targets
    if args.sort_by:
        targets = targets.sort_values(by=args.sort_by)

    if args.multichain:
        # Sort entries in group key to make comparison independent of order
        targets[args.group_key] = targets[args.group_key].apply(
            lambda x: ";".join(sorted(x.split(";")))
        )
    targets_group = targets.groupby(args.group_key)
    targets = targets_group.agg(list)

    if args.add_group_index_file:
        group_index = targets_group.cumcount() + 1  # 1-based index
        targets_with_index = targets.copy()
        targets_with_index[args.group_index_name] = group_index
        targets_with_index.to_csv(
            args.add_group_index_file, float_format="%.3f", index=False
        )
    merge = args.merge if args.merge else []
    for col in targets.columns:
        if col in merge:
            targets[col + "_"] = targets[col].apply(
                lambda x: x[0] if len(x) > 0 else None
            )
            targets[col] = targets[col].apply(lambda x: ";".join(map(str, x)))
        else:
            targets[col] = targets[col].apply(lambda x: x[0] if len(x) > 0 else None)

    targets = targets.reset_index()

    if args.rename:
        # Do the sequential rename instead of one shot to avoid conflicts, renames are applied in order
        for old_name, new_name in args.rename:
            print(f"Renaming column: {old_name} -> {new_name}")
            # drop exising columns to avoid conflicts
            targets = targets.drop(columns=[new_name], errors="ignore")
            targets = targets.rename(columns={old_name: new_name}, errors="raise")
    if args.sort_by_after:
        targets = targets.sort_values(by=args.sort_by_after)

    to_drop = args.drop if args.drop else []
    to_drop.extend([col for col in targets.columns if col.endswith("_")])
    if to_drop:
        targets = targets.drop(columns=to_drop)
    # Put pdb_id, chain_id, target_id, auth_chain_id, sequence  at the front if present
    front_cols = ["pdb_id", "chain_id", "target_id", "auth_chain_id", "sequence"]
    front_cols = [col for col in front_cols if col in targets.columns]
    other_cols = [col for col in targets.columns if col not in front_cols]
    targets = targets[front_cols + other_cols]

    targets.to_csv(
        output_file,
        float_format="%.3f",
        index=False,
    )
